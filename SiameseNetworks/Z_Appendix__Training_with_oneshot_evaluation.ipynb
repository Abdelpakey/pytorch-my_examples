{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix. Siamese neural networks training with one-shot learning evaluation\n",
    "\n",
    "This notebook presents the paper [\"Siamese Neural Networks for One-shot Image Recognition\"](https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf) coded with PyTorch framework. \n",
    "\n",
    "In this part we train Siamese network on the Omniglot dataset to perform the classification task to distinguish two images of the same class or different classes.\n",
    "\n",
    "Code is similar to `keras-oneshot`.\n",
    "\n",
    "References:\n",
    "- [paper](https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf)\n",
    "- [omniglot](https://github.com/brendenlake/omniglot)\n",
    "- [keras-oneshot](https://github.com/sorenbouma/keras-oneshot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAS_GPU = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup dataflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataflow import OmniglotDataset, SameOrDifferentPairsBatchDataset\n",
    "from common_utils.imgaug import RandomAffine, RandomApply\n",
    "from common_utils.dataflow import TransformedDataset, OnGPUDataLoader\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from torch.utils.data import DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 12345\n",
    "np.random.seed(seed)\n",
    "\n",
    "OMNIGLOT_REPO_PATH='omniglot'\n",
    "\n",
    "TRAIN_DATA_PATH = os.path.join(OMNIGLOT_REPO_PATH, 'python', 'images_background')\n",
    "train_alphabets = !ls {TRAIN_DATA_PATH}\n",
    "train_alphabets = list(train_alphabets)\n",
    "\n",
    "TEST_DATA_PATH = os.path.join(OMNIGLOT_REPO_PATH, 'python', 'images_evaluation')\n",
    "test_alphabets = !ls {TEST_DATA_PATH}\n",
    "test_alphabets = list(test_alphabets)\n",
    "\n",
    "assert len(train_alphabets) > 1 and len(test_alphabets) > 1, \"%s \\n %s\" % (train_alphabets[0], test_alphabets[0])\n",
    "\n",
    "train_alphabet_char_id_drawer_ids = {}\n",
    "for a in train_alphabets:\n",
    "    res = !ls \"{os.path.join(TRAIN_DATA_PATH, a)}\"\n",
    "    char_ids = list(res)\n",
    "    train_alphabet_char_id_drawer_ids[a] = {}\n",
    "    for char_id in char_ids:\n",
    "        res = !ls \"{os.path.join(TRAIN_DATA_PATH, a, char_id)}\"\n",
    "        train_alphabet_char_id_drawer_ids[a][char_id] = [_id[:-4] for _id in list(res)]\n",
    "        \n",
    "        \n",
    "test_alphabet_char_id_drawer_ids = {}\n",
    "for a in test_alphabets:\n",
    "    res = !ls \"{os.path.join(TEST_DATA_PATH, a)}\"\n",
    "    char_ids = list(res)\n",
    "    test_alphabet_char_id_drawer_ids[a] = {}\n",
    "    for char_id in char_ids:\n",
    "        res = !ls \"{os.path.join(TEST_DATA_PATH, a, char_id)}\"\n",
    "        test_alphabet_char_id_drawer_ids[a][char_id] = [_id[:-4] for _id in list(res)]\n",
    "\n",
    "\n",
    "# Sample 12 drawers out of 20\n",
    "all_drawers_ids = np.arange(20) \n",
    "train_drawers_ids = np.random.choice(all_drawers_ids, size=12, replace=False)\n",
    "# Sample 4 drawers out of remaining 8\n",
    "val_drawers_ids = np.random.choice(list(set(all_drawers_ids) - set(train_drawers_ids)), size=8, replace=False)\n",
    "\n",
    "def create_str_drawers_ids(drawers_ids):\n",
    "    return [\"_{0:0>2}\".format(_id) for _id in drawers_ids]\n",
    "\n",
    "train_drawers_ids = create_str_drawers_ids(train_drawers_ids)\n",
    "val_drawers_ids = create_str_drawers_ids(val_drawers_ids)\n",
    "\n",
    "train_ds = OmniglotDataset(\"Train\", data_path=TRAIN_DATA_PATH, \n",
    "                           alphabet_char_id_drawers_ids=train_alphabet_char_id_drawer_ids, \n",
    "                           drawers_ids=train_drawers_ids)\n",
    "\n",
    "val_ds = OmniglotDataset(\"Test\", data_path=TEST_DATA_PATH, \n",
    "                         alphabet_char_id_drawers_ids=test_alphabet_char_id_drawer_ids, \n",
    "                         drawers_ids=val_drawers_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_aug = Compose([\n",
    "    RandomApply(\n",
    "        RandomAffine(rotation=(-10, 10), scale=(0.8, 1.2), translate=(-0.05, 0.05)),\n",
    "        proba=0.5\n",
    "    ),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "test_data_aug = Compose([\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "nb_train_batches = 100\n",
    "nb_val_batches = 100\n",
    "\n",
    "train_batches = SameOrDifferentPairsBatchDataset(train_ds,\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 nb_batches=nb_train_batches,\n",
    "                                                 x_transforms=train_data_aug,\n",
    "                                                 pin_memory=HAS_GPU, on_gpu=HAS_GPU)\n",
    "\n",
    "val_batches = SameOrDifferentPairsBatchDataset(val_ds,\n",
    "                                               batch_size=batch_size,\n",
    "                                               nb_batches=nb_val_batches,\n",
    "                                               x_transforms=test_data_aug,\n",
    "                                               pin_memory=HAS_GPU, on_gpu=HAS_GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 105, 105]) torch.Size([64, 1, 105, 105]) torch.Size([64, 1])\n",
      "<class 'torch.cuda.FloatTensor'> <class 'torch.cuda.FloatTensor'> <class 'torch.cuda.FloatTensor'>\n"
     ]
    }
   ],
   "source": [
    "for (x1, x2), y in train_batches:\n",
    "    print(x1.size(), x2.size(), y.size())\n",
    "    print(type(x1), type(x1), type(y))    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#     def make_oneshot_task(self,N,s=\"val\",language=None):\n",
    "#         \"\"\"Create pairs of test image, support set for testing N way one-shot learning. \"\"\"\n",
    "#         X=self.data[s]\n",
    "#         n_classes, n_examples = X.shape[0],X.shape[1]\n",
    "#         if language is not None:\n",
    "#             low, high = self.categories[s][language]\n",
    "#             if N > high - low:\n",
    "#                 raise ValueError(\"This language ({}) has less than {} letters\".format(language, N))\n",
    "#             categories = rng.choice(range(low,high),size=(N,),replace=False)\n",
    "#             indices = rng.randint(0,self.n_examples,size=(N,))\n",
    "            \n",
    "#         else:#if no language specified just pick a bunch of random letters\n",
    "#             categories = rng.choice(range(n_classes),size=(N,),replace=False)            \n",
    "#             indices = rng.randint(0,self.n_examples,size=(N,))\n",
    "#         true_category = categories[0]\n",
    "#         ex1, ex2 = rng.choice(n_examples,replace=False,size=(2,))\n",
    "#         test_image = np.asarray([X[true_category,ex1,:,:]]*N).reshape(N,self.w,self.h,1)\n",
    "#         support_set = X[categories,indices,:,:]\n",
    "#         support_set[0,:,:] = X[true_category,ex2]\n",
    "#         support_set = support_set.reshape(N,self.w,self.h,1)\n",
    "#         targets = np.zeros((N,))\n",
    "#         targets[0] = 1\n",
    "#         targets, test_image, support_set = shuffle(targets, test_image, support_set)\n",
    "#         pairs = [test_image,support_set]\n",
    "\n",
    "#         return pairs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, Sampler\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class OneShotLearningDataset2(Dataset):\n",
    "    \n",
    "    def __init__(self, n_trials, n_classes, ds, class_indices=None,\n",
    "                 x_transforms=None, y_transforms=None,\n",
    "                 pin_memory=True, on_gpu=True):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super(OneShotLearningDataset2, self).__init__()\n",
    "\n",
    "        self.n_trials = n_trials                \n",
    "        self.n_classes = n_classes        \n",
    "        self.ds = ds\n",
    "        self.pin_memory = pin_memory\n",
    "        self.on_gpu = on_gpu\n",
    "        \n",
    "        self.x_transforms = x_transforms if x_transforms is not None else lambda x: x\n",
    "        self.y_transforms = y_transforms if y_transforms is not None else lambda y: y\n",
    "        \n",
    "        if class_indices is None:\n",
    "            # get mapping y_label -> indices\n",
    "            class_indices = defaultdict(list)\n",
    "            for i, (_, y) in enumerate(ds):\n",
    "                class_indices[y].append(i)\n",
    "\n",
    "        self.class_indices = class_indices\n",
    "        self.classes = list(self.class_indices.keys())\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.n_trials)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        if index >= self.n_trials:\n",
    "            raise IndexError()\n",
    "            \n",
    "        random_classes = np.random.choice(self.classes, size=(self.n_classes, ), replace=False)        \n",
    "        \n",
    "#         support_set_indices = []        \n",
    "#         for indices in self.class_indices.values():\n",
    "#             index = np.random.randint(len(indices))\n",
    "#             support_set_indices.append(indices[index])\n",
    "#         np.random.shuffle(support_set_indices)\n",
    "\n",
    "        true_class = random_classes[0]\n",
    "        n_samples = len(self.class_indices[true_class])\n",
    "        index1 = np.random.randint(0, n_samples)\n",
    "        test_x, _ = self.ds[self.class_indices[true_class][index1]]\n",
    "                \n",
    "        targets = np.zeros((self.n_classes,), dtype=np.int)\n",
    "        targets[0] = 1\n",
    "        targets = torch.from_numpy(targets)\n",
    "\n",
    "        \n",
    "        \n",
    "#        categories = rng.choice(range(n_classes),size=(N,),replace=False)                    \n",
    "#        indices = rng.randint(0,self.n_examples,size=(N,))\n",
    "\n",
    "#         true_category = categories[0]\n",
    "#         ex1, ex2 = rng.choice(n_examples,replace=False,size=(2,))\n",
    "#         test_image = np.asarray([X[true_category,ex1,:,:]]*N).reshape(N,self.w,self.h,1)\n",
    "#         support_set = X[categories,indices,:,:]\n",
    "#         support_set[0,:,:] = X[true_category,ex2]\n",
    "#         support_set = support_set.reshape(N,self.w,self.h,1)\n",
    "#         targets = np.zeros((N,))\n",
    "#         targets[0] = 1\n",
    "#         targets, test_image, support_set = shuffle(targets, test_image, support_set)\n",
    "#         pairs = [test_image,support_set]\n",
    "\n",
    "        return pairs, targets        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup model, loss function and optimisation algorithm\n",
    "\n",
    "#### Weight regularization\n",
    "\n",
    "L2 weights regularization: \n",
    "\n",
    "#### Loss function\n",
    "\n",
    "Binary cross-entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.nn.functional import sigmoid\n",
    "from torch.optim import Adam, RMSprop, SGD\n",
    "from torch.optim.lr_scheduler import ExponentialLR, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from common_utils.training_utils import train_one_epoch, validate, write_csv_log, write_conf_log, verbose_optimizer, save_checkpoint\n",
    "from common_utils.training_utils import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import SiameseNetworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_net = SiameseNetworks(input_shape=(105, 105, 1))\n",
    "if HAS_GPU and torch.cuda.is_available():\n",
    "    siamese_net = siamese_net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {\n",
    "    'weight_decay': 0.01,\n",
    "    \n",
    "    'lr_features': 0.00006,\n",
    "    'lr_classifier': 0.00006,\n",
    "    \n",
    "    'n_epochs': 15,    \n",
    "    'gamma': 0.99\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_logits(y_logits, y_true):\n",
    "    y_pred = sigmoid(y_logits).data\n",
    "    return accuracy(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = BCEWithLogitsLoss()\n",
    "if HAS_GPU and torch.cuda.is_available():\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.cuda.FloatTensor'> <class 'torch.cuda.FloatTensor'> torch.Size([64, 1]) torch.Size([64, 1])\n",
      "Loss :  \n",
      " 0.7024\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Accuracy :  0.453125\n"
     ]
    }
   ],
   "source": [
    "# Test single forward pass and loss function computation\n",
    "siamese_net.eval()\n",
    "for i, ((batch_x1, batch_x2), batch_y) in enumerate(train_batches):\n",
    "    \n",
    "    batch_x1 = Variable(batch_x1, requires_grad=True)\n",
    "    batch_x2 = Variable(batch_x2, requires_grad=True)    \n",
    "    batch_y = Variable(batch_y)\n",
    "    batch_y_logits = siamese_net(batch_x1, batch_x2)\n",
    "    print(type(batch_y.data), type(batch_y_logits.data), batch_y.size(), batch_y_logits.size())    \n",
    "    loss = criterion(batch_y_logits, batch_y)\n",
    "    print(\"Loss : \", loss.data)\n",
    "    \n",
    "    print(\"Accuracy : \", accuracy_logits(batch_y_logits.data, batch_y.data))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam([{\n",
    "    'params': siamese_net.net.features.parameters(),\n",
    "    'lr': conf['lr_features'],    \n",
    "}, {\n",
    "    'params': siamese_net.classifier.parameters(),\n",
    "    'lr': conf['lr_classifier']\n",
    "}],\n",
    "    weight_decay=conf['weight_decay']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we define L2 regularization weights through optimizer API as `weight_decay` parameter, [ref](http://pytorch.org/docs/master/optim.html?highlight=adam#torch.optim.Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr <- lr_init * gamma ** epoch\n",
    "scheduler = ExponentialLR(optimizer, gamma=conf['gamma'])\n",
    "onplateau_scheduler = ReduceLROnPlateau(optimizer, factor=0.5, patience=2, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "logs_path = os.path.join('logs', 'siamese_networks_verification_task_%s' % (now.strftime(\"%Y%m%d_%H%M\")))\n",
    "if not os.path.exists(logs_path):\n",
    "    os.makedirs(logs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tinitial_lr: 6e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tlr: 6e-05\n",
      "- Param group: \n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tinitial_lr: 6e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tlr: 6e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15: 100%|##########| 100/100 [00:08<00:00, 11.24it/s, Loss 0.6124 | accuracy_logits 0.647]\n",
      "100%|##########| 100/100 [00:04<00:00, 23.54it/s, Loss 0.6022 | accuracy_logits 0.673]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tinitial_lr: 6e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tlr: 5.94e-05\n",
      "- Param group: \n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tinitial_lr: 6e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tlr: 5.94e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2/15: 100%|##########| 100/100 [00:08<00:00, 11.18it/s, Loss 0.6002 | accuracy_logits 0.669]\n",
      "100%|##########| 100/100 [00:04<00:00, 23.55it/s, Loss 0.6208 | accuracy_logits 0.666]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tinitial_lr: 6e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tlr: 5.8806e-05\n",
      "- Param group: \n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tinitial_lr: 6e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tlr: 5.8806e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3/15: 100%|##########| 100/100 [00:08<00:00, 11.20it/s, Loss 0.5781 | accuracy_logits 0.694]\n",
      "100%|##########| 100/100 [00:04<00:00, 23.50it/s, Loss 0.6297 | accuracy_logits 0.690]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tinitial_lr: 6e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tlr: 5.821794e-05\n",
      "- Param group: \n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tinitial_lr: 6e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tlr: 5.821794e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4/15: 100%|##########| 100/100 [00:08<00:00, 11.11it/s, Loss 0.5659 | accuracy_logits 0.711]\n",
      "100%|##########| 100/100 [00:04<00:00, 23.48it/s, Loss 0.5962 | accuracy_logits 0.700]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tinitial_lr: 6e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tlr: 5.7635760599999995e-05\n",
      "- Param group: \n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tinitial_lr: 6e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tlr: 5.7635760599999995e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5/15: 100%|##########| 100/100 [00:08<00:00, 11.17it/s, Loss 0.5512 | accuracy_logits 0.718]\n",
      "100%|##########| 100/100 [00:04<00:00, 23.16it/s, Loss 0.5784 | accuracy_logits 0.718]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tinitial_lr: 6e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tlr: 5.7059402994e-05\n",
      "- Param group: \n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tinitial_lr: 6e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tlr: 5.7059402994e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6/15: 100%|##########| 100/100 [00:08<00:00, 11.08it/s, Loss 0.5576 | accuracy_logits 0.718]\n",
      "100%|##########| 100/100 [00:04<00:00, 23.26it/s, Loss 0.5665 | accuracy_logits 0.728]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tinitial_lr: 6e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tlr: 5.6488808964060004e-05\n",
      "- Param group: \n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tinitial_lr: 6e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tlr: 5.6488808964060004e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 7/15: 100%|##########| 100/100 [00:08<00:00, 11.17it/s, Loss 0.5297 | accuracy_logits 0.741]\n",
      "100%|##########| 100/100 [00:04<00:00, 23.27it/s, Loss 0.5624 | accuracy_logits 0.731]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tinitial_lr: 6e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tlr: 5.5923920874419396e-05\n",
      "- Param group: \n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tinitial_lr: 6e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tlr: 5.5923920874419396e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 8/15: 100%|##########| 100/100 [00:08<00:00, 11.08it/s, Loss 0.5059 | accuracy_logits 0.762]\n",
      "100%|##########| 100/100 [00:04<00:00, 23.27it/s, Loss 0.5397 | accuracy_logits 0.745]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tinitial_lr: 6e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tlr: 5.536468166567521e-05\n",
      "- Param group: \n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tinitial_lr: 6e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tlr: 5.536468166567521e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9/15: 100%|##########| 100/100 [00:08<00:00, 11.17it/s, Loss 0.4868 | accuracy_logits 0.775]\n",
      "100%|##########| 100/100 [00:04<00:00, 23.21it/s, Loss 0.5411 | accuracy_logits 0.750]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tinitial_lr: 6e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tlr: 5.4811034849018454e-05\n",
      "- Param group: \n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tinitial_lr: 6e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tlr: 5.4811034849018454e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 10/15: 100%|##########| 100/100 [00:08<00:00, 11.15it/s, Loss 0.4973 | accuracy_logits 0.772]\n",
      "100%|##########| 100/100 [00:04<00:00, 23.23it/s, Loss 0.5696 | accuracy_logits 0.741]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tinitial_lr: 6e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tlr: 5.4262924500528266e-05\n",
      "- Param group: \n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tinitial_lr: 6e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tlr: 5.4262924500528266e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 11/15: 100%|##########| 100/100 [00:08<00:00, 11.14it/s, Loss 0.4720 | accuracy_logits 0.785]\n",
      "100%|##########| 100/100 [00:04<00:00, 23.21it/s, Loss 0.5487 | accuracy_logits 0.760]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    10: reducing learning rate of group 0 to 2.7131e-05.\n",
      "Epoch    10: reducing learning rate of group 1 to 2.7131e-05.\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tinitial_lr: 6e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tlr: 5.372029525552299e-05\n",
      "- Param group: \n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tinitial_lr: 6e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tlr: 5.372029525552299e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 12/15: 100%|##########| 100/100 [00:08<00:00, 11.12it/s, Loss 0.4681 | accuracy_logits 0.792]\n",
      "100%|##########| 100/100 [00:04<00:00, 23.23it/s, Loss 0.4785 | accuracy_logits 0.793]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tinitial_lr: 6e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tlr: 5.3183092302967755e-05\n",
      "- Param group: \n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tinitial_lr: 6e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tlr: 5.3183092302967755e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 13/15: 100%|##########| 100/100 [00:08<00:00, 11.19it/s, Loss 0.4511 | accuracy_logits 0.794]\n",
      "100%|##########| 100/100 [00:04<00:00, 23.25it/s, Loss 0.5002 | accuracy_logits 0.778]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tinitial_lr: 6e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tlr: 5.2651261379938074e-05\n",
      "- Param group: \n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tinitial_lr: 6e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tlr: 5.2651261379938074e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 14/15: 100%|##########| 100/100 [00:08<00:00, 11.18it/s, Loss 0.4438 | accuracy_logits 0.804]\n",
      "100%|##########| 100/100 [00:04<00:00, 23.23it/s, Loss 0.4868 | accuracy_logits 0.791]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tinitial_lr: 6e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tlr: 5.2124748766138696e-05\n",
      "- Param group: \n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tinitial_lr: 6e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tlr: 5.2124748766138696e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15/15: 100%|##########| 100/100 [00:08<00:00, 11.08it/s, Loss 0.4358 | accuracy_logits 0.808]\n",
      "100%|##########| 100/100 [00:04<00:00, 23.25it/s, Loss 0.5162 | accuracy_logits 0.776]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    14: reducing learning rate of group 0 to 2.6062e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 2.6062e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "write_conf_log(logs_path, \"{}\".format(conf))\n",
    "write_conf_log(logs_path, verbose_optimizer(optimizer))\n",
    "\n",
    "write_csv_log(logs_path, \"epoch,train_loss,train_acc,val_loss,val_acc\")\n",
    "\n",
    "best_acc = 0.0\n",
    "for epoch in range(conf['n_epochs']):\n",
    "    scheduler.step()\n",
    "    # Verbose learning rates:\n",
    "    print(verbose_optimizer(optimizer))\n",
    "\n",
    "    # train for one epoch\n",
    "    ret = train_one_epoch(siamese_net, train_batches, \n",
    "                          criterion, optimizer,                                               \n",
    "                          epoch, conf['n_epochs'], avg_metrics=[accuracy_logits,])\n",
    "    if ret is None:\n",
    "        break\n",
    "    train_loss, train_acc = ret\n",
    "\n",
    "    # evaluate on validation set\n",
    "    ret = validate(siamese_net, val_batches, criterion, avg_metrics=[accuracy_logits, ])\n",
    "    if ret is None:\n",
    "        break\n",
    "    val_loss, val_acc = ret\n",
    "    \n",
    "    onplateau_scheduler.step(val_loss)\n",
    "\n",
    "    # Write a csv log file\n",
    "    write_csv_log(logs_path, \"%i,%f,%f,%f,%f\" % (epoch, train_loss, train_acc, val_loss, val_acc))\n",
    "\n",
    "    # remember best accuracy and save checkpoint\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = max(val_acc, best_acc)\n",
    "        save_checkpoint(logs_path, 'val_acc', \n",
    "                        {'epoch': epoch + 1,\n",
    "                         'state_dict': siamese_net.state_dict(),\n",
    "                         'val_acc': val_acc,           \n",
    "                         'optimizer': optimizer.state_dict()})        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_classes = list(class_indices.keys()) \n",
    "y_transform = lambda y: torch.LongTensor([list_of_classes.index(y)])\n",
    "\n",
    "val_aug_ds = TransformedDataset(val_ds, x_transforms=test_data_aug, y_transforms=y_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import Sampler\n",
    "\n",
    "class RandomSupportSetSampler(Sampler):\n",
    "    \"\"\"\n",
    "    Random support set samplers for one-shot learning\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, class_indices, seed=None):\n",
    "        \"\"\"\n",
    "        :params class_indices: dictionary key=targets of `ds`, values=indices of `ds` corresponding to target\n",
    "            Number N of N-way evalution is defined by number of keys in the dictionary         \n",
    "            It can be obtained from a dataset with something like:\n",
    "            ```\n",
    "                class_indices = defaultdict(list)\n",
    "                for i, (_, y) in enumerate(val_ds):\n",
    "                    class_indices[y].append(i)\n",
    "            ```\n",
    "        \"\"\"\n",
    "        assert isinstance(class_indices, dict)\n",
    "        self.class_indices = class_indices\n",
    "        self.seed = seed\n",
    "        \n",
    "    def __iter__(self):\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        support_set_indices = []        \n",
    "        for indices in self.class_indices.values():\n",
    "            index = np.random.randint(len(indices))\n",
    "            support_set_indices.append(indices[index])\n",
    "        np.random.shuffle(support_set_indices)\n",
    "        return iter(support_set_indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class_indices = defaultdict(list)\n",
    "for i, (_, y) in enumerate(val_aug_ds):\n",
    "    y = y.numpy()[0] \n",
    "    class_indices[y].append(i)\n",
    "\n",
    "sampler = RandomSupportSetSampler(class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import  DataLoader\n",
    "\n",
    "\n",
    "def generate_support_set(ds, class_indices, seed=None, **kwargs):\n",
    "    assert isinstance(class_indices, dict)\n",
    "    assert isinstance(ds, Dataset)\n",
    "    \n",
    "    sampler = RandomSupportSetSampler(class_indices, seed)    \n",
    "    data_loader = DataLoader(ds, batch_size=len(sampler), sampler=sampler, **kwargs)   \n",
    "    return data_loader\n",
    "\n",
    "\n",
    "def generate_test_dataset(ds, n_classes):\n",
    "    for x, y in ds:\n",
    "        x\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_set = generate_support_set(val_aug_ds, class_indices, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.FloatTensor'> torch.Size([659, 1, 105, 105]) <class 'torch.LongTensor'> torch.Size([659, 1])\n"
     ]
    }
   ],
   "source": [
    "for set_x, set_y in support_set:\n",
    "    print(type(set_x), set_x.size(), type(set_y), set_y.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, Sampler\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class OneShotLearningDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, test_ds, val_ds, val_class_indices=None, n=None,\n",
    "                 seed=None, on_gpu=True, **kwargs):\n",
    "        \"\"\"\n",
    "        Dataset for one-shot learning. It contains lenght of `test_ds` elements and at index `i` \n",
    "        returns `(test_x, support_set_x), (test_y, support_set_y)` where `test_x`, `test_y` are N copies of \n",
    "        a single data given by `test_ds[i]`. Variables `support_set_x`, `support_set_y` are tensors of N elements \n",
    "        from `val_ds` belonging to N different classes.\n",
    "         \n",
    "        :params test_ds: dataset that provides test data.\n",
    "        :params val_ds: dataset from which to select a support set\n",
    "        :params val_class_indices: dictionary key=targets of `val_ds`, values=indices of `val_ds` corresponding to target\n",
    "            Number N of N-way evalution is defined by number of keys             \n",
    "        :params **kwargs: for DataLoader\n",
    "        \"\"\"\n",
    "        super(OneShotLearningDataset, self).__init__()\n",
    "        \n",
    "        if val_class_indices is None:\n",
    "            val_class_indices = defaultdict(list)            \n",
    "            for i, (_, y) in enumerate(val_ds):\n",
    "                if torch.is_tensor(y):\n",
    "                    y = y.numpy()[0] \n",
    "                val_class_indices[y].append(i)\n",
    "\n",
    "        assert isinstance(val_class_indices, dict)\n",
    "        \n",
    "        self.test_ds = test_ds\n",
    "        self.val_ds = val_ds\n",
    "        self.val_class_indices = val_class_indices\n",
    "        self.on_gpu = on_gpu\n",
    "        \n",
    "        sampler = RandomSupportSetSampler(val_class_indices, seed)    \n",
    "        self.support_set_ds = DataLoader(self.val_ds, batch_size=len(sampler), sampler=sampler, **kwargs)   \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.test_ds)\n",
    "    \n",
    "    def __getitem__(self, index):        \n",
    "        test_x, test_y = self.test_ds[index]\n",
    "\n",
    "        for support_set_x, support_set_y in self.support_set_ds:\n",
    "            break\n",
    "\n",
    "        if self.on_gpu:\n",
    "            test_x = test_x.cuda()\n",
    "            test_y = test_y.cuda()\n",
    "            support_set_x = support_set_x.cuda()    \n",
    "            support_set_y = support_set_y.cuda()\n",
    "                \n",
    "        test_x = test_x.expand_as(support_set_x)\n",
    "        test_y = test_y.expand_as(support_set_y)\n",
    "            \n",
    "        return (test_x, support_set_x), (test_y, support_set_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = OneShotLearningDataset(val_aug_ds, val_aug_ds)    \n",
    "# val_acc = 0.0\n",
    "# for (test_x, support_set_x), (test_y, support_set_y) in ds:\n",
    "    \n",
    "#     test_x = Variable(test_x, volatile=True)\n",
    "#     support_set_x = Variable(support_set_x, volatile=True)    \n",
    "    \n",
    "#     y_logits = siamese_net(test_x, support_set_x)\n",
    "#     y_proba = sigmoid(y_logits).data\n",
    "\n",
    "#     if len(y_proba.size()) > 1:\n",
    "#         y_proba = y_proba.view(-1)        \n",
    "\n",
    "#     y_proba_top1, index_top1 = y_proba.topk(k=1, largest=True, dim=0)\n",
    "#     if index_top1.is_cuda:\n",
    "#         index_top1 = index_top1.cpu()    \n",
    "\n",
    "#     classes_top1 = support_set_y[index_top1[0], 0]\n",
    "\n",
    "#     if test_y[0, 0] == classes_top1:\n",
    "#         val_acc += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common_utils.training_utils import get_tqdm\n",
    "\n",
    "def oneshot_learning_validation(model, val_ds, n=20):\n",
    "    \n",
    "    model.eval()\n",
    "    try:\n",
    "        ds = OneShotLearningDataset(val_aug_ds, val_aug_ds)    \n",
    "        val_acc = 0.0\n",
    "\n",
    "        with get_tqdm(total=len(ds)) as pbar:\n",
    "            for (test_x, support_set_x), (test_y, support_set_y) in ds:\n",
    "                \n",
    "                test_x = Variable(test_x, volatile=True)\n",
    "                support_set_x = Variable(support_set_x, volatile=True)    \n",
    "\n",
    "                y_logits = model(test_x, support_set_x)\n",
    "                y_proba = sigmoid(y_logits).data\n",
    "\n",
    "                if len(y_proba.size()) > 1:\n",
    "                    y_proba = y_proba.view(-1)        \n",
    "\n",
    "                y_proba_top1, index_top1 = y_proba.topk(k=1, largest=True, dim=0)\n",
    "                if index_top1.is_cuda:\n",
    "                    index_top1 = index_top1.cpu()    \n",
    "\n",
    "                classes_top1 = support_set_y[index_top1[0], 0]\n",
    "\n",
    "                if test_y[0, 0] == classes_top1:\n",
    "                    val_acc += 1\n",
    "                    \n",
    "                prefix_str = \"One-shot learning eval : \"\n",
    "                pbar.set_description_str(prefix_str, refresh=False)\n",
    "                    \n",
    "                post_fix_str = \"Accuracy: {}\".format(val_acc)\n",
    "                pbar.set_postfix_str(post_fix_str, refresh=False)\n",
    "                pbar.update(1)            \n",
    "        \n",
    "        val_acc /= 1.0 * len(ds)\n",
    "        return val_acc                    \n",
    "    except KeyboardInterrupt:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One-shot learning eval :   2%|2         | 126/5272 [00:35<24:04,  3.56it/s, Accuracy: 1.0]\n"
     ]
    }
   ],
   "source": [
    "val_acc = oneshot_learning_validation(siamese_net, val_aug_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference on testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common_utils.training_utils import load_checkpoint\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load checkpoint: logs/siamese_networks_verification_task_20171126_1148/model_val_acc=0.7575.pth.tar\n"
     ]
    }
   ],
   "source": [
    "best_model_filenames = glob(os.path.join(logs_path, \"model_val_acc=*\"))\n",
    "assert len(best_model_filenames) == 1\n",
    "load_checkpoint(best_model_filenames[0], siamese_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 157/157 [00:04<00:00, 34.78it/s, Loss 0.5082 | accuracy_logits 0.754]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5081654835700988, 0.754)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate on validation set\n",
    "test_loss, test_acc = validate(siamese_net, test_batches, criterion, avg_metrics=[accuracy_logits, ])\n",
    "test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 6e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "- Param group: \n",
      "\tinitial_lr: 8e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 8e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "\n",
      "Epoch: 1/50: 100%|#| 468/468 [00:42<00:00, 10.94it/s, Loss 0.6231 | accuracy_logits 0.631]\n",
      "100%|####| 156/156 [00:04<00:00, 35.05it/s, Loss 0.5816 | accuracy_logits 0.687]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 5.4000000000000005e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "- Param group: \n",
      "\tinitial_lr: 8e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 7.2e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "\n",
      "Epoch: 2/50: 100%|#| 468/468 [00:42<00:00, 11.03it/s, Loss 0.5697 | accuracy_logits 0.701]\n",
      "100%|####| 156/156 [00:04<00:00, 35.79it/s, Loss 0.5615 | accuracy_logits 0.718]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 4.86e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "- Param group: \n",
      "\tinitial_lr: 8e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 6.48e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "\n",
      "Epoch: 3/50: 100%|#| 468/468 [00:42<00:00, 11.00it/s, Loss 0.5057 | accuracy_logits 0.755]\n",
      "100%|####| 156/156 [00:04<00:00, 35.79it/s, Loss 0.5048 | accuracy_logits 0.751]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 4.3740000000000005e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "- Param group: \n",
      "\tinitial_lr: 8e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 5.832000000000001e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "\n",
      "Epoch: 4/50: 100%|#| 468/468 [00:42<00:00, 10.99it/s, Loss 0.4356 | accuracy_logits 0.801]\n",
      "100%|####| 156/156 [00:04<00:00, 35.55it/s, Loss 0.4489 | accuracy_logits 0.789]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 3.9366e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "- Param group: \n",
      "\tinitial_lr: 8e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 5.2488e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "\n",
      "Epoch: 5/50: 100%|#| 468/468 [00:42<00:00, 11.10it/s, Loss 0.3859 | accuracy_logits 0.832]\n",
      "100%|####| 156/156 [00:04<00:00, 35.63it/s, Loss 0.4634 | accuracy_logits 0.787]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 3.54294e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "- Param group: \n",
      "\tinitial_lr: 8e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 4.723920000000001e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "\n",
      "Epoch: 6/50: 100%|#| 468/468 [00:42<00:00, 11.01it/s, Loss 0.3478 | accuracy_logits 0.854]\n",
      "100%|####| 156/156 [00:04<00:00, 35.75it/s, Loss 0.4211 | accuracy_logits 0.804]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 3.1886460000000004e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "- Param group: \n",
      "\tinitial_lr: 8e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 4.251528000000001e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "\n",
      "Epoch: 7/50: 100%|#| 468/468 [00:42<00:00, 10.98it/s, Loss 0.3295 | accuracy_logits 0.864]\n",
      "100%|####| 156/156 [00:04<00:00, 35.90it/s, Loss 0.4134 | accuracy_logits 0.816]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 2.8697814000000007e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "- Param group: \n",
      "\tinitial_lr: 8e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 3.8263752000000007e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "\n",
      "Epoch: 8/50: 100%|#| 468/468 [00:42<00:00, 10.97it/s, Loss 0.3094 | accuracy_logits 0.876]\n",
      "100%|####| 156/156 [00:04<00:00, 35.65it/s, Loss 0.3973 | accuracy_logits 0.824]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 2.5828032600000008e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "- Param group: \n",
      "\tinitial_lr: 8e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 3.443737680000001e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "\n",
      "Epoch: 9/50: 100%|#| 468/468 [00:42<00:00, 10.97it/s, Loss 0.2927 | accuracy_logits 0.883]\n",
      "100%|####| 156/156 [00:04<00:00, 35.49it/s, Loss 0.3882 | accuracy_logits 0.831]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 2.3245229340000006e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "- Param group: \n",
      "\tinitial_lr: 8e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 3.099363912000001e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "\n",
      "Epoch: 10/50: 100%|#| 468/468 [00:42<00:00, 11.00it/s, Loss 0.2793 | accuracy_logits 0.891]\n",
      "100%|####| 156/156 [00:04<00:00, 35.85it/s, Loss 0.3685 | accuracy_logits 0.839]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 2.0920706406000006e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "- Param group: \n",
      "\tinitial_lr: 8e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 2.789427520800001e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "\n",
      "Epoch: 11/50: 100%|#| 468/468 [00:42<00:00, 10.95it/s, Loss 0.2665 | accuracy_logits 0.899]\n",
      "100%|####| 156/156 [00:04<00:00, 35.49it/s, Loss 0.3810 | accuracy_logits 0.831]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 1.8828635765400005e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "- Param group: \n",
      "\tinitial_lr: 8e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 2.5104847687200008e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "\n",
      "Epoch: 12/50: 100%|#| 468/468 [00:42<00:00, 10.96it/s, Loss 0.2582 | accuracy_logits 0.902]\n",
      "100%|####| 156/156 [00:04<00:00, 35.56it/s, Loss 0.3629 | accuracy_logits 0.841]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 1.694577218886001e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "- Param group: \n",
      "\tinitial_lr: 8e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 2.259436291848001e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "\n",
      "Epoch: 13/50: 100%|#| 468/468 [00:42<00:00, 10.99it/s, Loss 0.2465 | accuracy_logits 0.908]\n",
      "100%|####| 156/156 [00:04<00:00, 35.60it/s, Loss 0.3714 | accuracy_logits 0.837]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 1.5251194969974005e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "- Param group: \n",
      "\tinitial_lr: 8e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 2.0334926626632008e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "\n",
      "Epoch: 14/50: 100%|#| 468/468 [00:42<00:00, 10.91it/s, Loss 0.2422 | accuracy_logits 0.911]\n",
      "100%|####| 156/156 [00:04<00:00, 35.14it/s, Loss 0.3675 | accuracy_logits 0.838]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 1.3726075472976605e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "- Param group: \n",
      "\tinitial_lr: 8e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 1.8301433963968808e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "\n",
      "Epoch: 15/50: 100%|#| 468/468 [00:42<00:00, 10.98it/s, Loss 0.2342 | accuracy_logits 0.914]\n",
      "100%|####| 156/156 [00:04<00:00, 35.64it/s, Loss 0.3553 | accuracy_logits 0.844]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 1.2353467925678944e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "- Param group: \n",
      "\tinitial_lr: 8e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 1.6471290567571928e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "\n",
      "Epoch: 16/50: 100%|#| 468/468 [00:43<00:00, 10.88it/s, Loss 0.2279 | accuracy_logits 0.917]\n",
      "100%|####| 156/156 [00:04<00:00, 35.09it/s, Loss 0.3573 | accuracy_logits 0.845]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 1.111812113311105e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "- Param group: \n",
      "\tinitial_lr: 8e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 1.4824161510814735e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "\n",
      "Epoch: 17/50: 100%|#| 468/468 [00:42<00:00, 10.90it/s, Loss 0.2223 | accuracy_logits 0.919]\n",
      "100%|####| 156/156 [00:04<00:00, 35.23it/s, Loss 0.3526 | accuracy_logits 0.847]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 1.0006309019799946e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "- Param group: \n",
      "\tinitial_lr: 8e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 1.3341745359733262e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "\n",
      "Epoch: 18/50: 100%|#| 468/468 [00:42<00:00, 10.96it/s, Loss 0.2218 | accuracy_logits 0.922]\n",
      "100%|####| 156/156 [00:04<00:00, 35.89it/s, Loss 0.3455 | accuracy_logits 0.850]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 9.005678117819951e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "- Param group: \n",
      "\tinitial_lr: 8e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 1.2007570823759936e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "\n",
      "Epoch: 19/50: 100%|#| 468/468 [00:42<00:00, 11.00it/s, Loss 0.2145 | accuracy_logits 0.926]\n",
      "100%|####| 156/156 [00:04<00:00, 35.57it/s, Loss 0.3437 | accuracy_logits 0.849]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 8.105110306037958e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "- Param group: \n",
      "\tinitial_lr: 8e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 1.0806813741383944e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/50: 100%|#| 468/468 [00:43<00:00, 10.91it/s, Loss 0.2109 | accuracy_logits 0.927]\n",
      "100%|####| 156/156 [00:04<00:00, 35.62it/s, Loss 0.3449 | accuracy_logits 0.847]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 7.294599275434162e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "- Param group: \n",
      "\tinitial_lr: 8e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 9.726132367245548e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "\n",
      "Epoch: 21/50: 100%|#| 468/468 [00:42<00:00, 11.04it/s, Loss 0.2073 | accuracy_logits 0.930]\n",
      "100%|####| 156/156 [00:04<00:00, 35.62it/s, Loss 0.3419 | accuracy_logits 0.853]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 6.5651393478907455e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "- Param group: \n",
      "\tinitial_lr: 8e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 8.753519130520995e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "\n",
      "Epoch: 22/50: 100%|#| 468/468 [00:43<00:00, 10.81it/s, Loss 0.2062 | accuracy_logits 0.929]\n",
      "100%|####| 156/156 [00:04<00:00, 35.65it/s, Loss 0.3448 | accuracy_logits 0.847]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 5.908625413101671e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "- Param group: \n",
      "\tinitial_lr: 8e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 7.878167217468896e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "\n",
      "Epoch: 23/50: 100%|#| 468/468 [00:43<00:00, 10.80it/s, Loss 0.2002 | accuracy_logits 0.932]\n",
      "100%|####| 156/156 [00:04<00:00, 35.67it/s, Loss 0.3502 | accuracy_logits 0.845]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 5.317762871791504e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "- Param group: \n",
      "\tinitial_lr: 8e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 7.090350495722006e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "\n",
      "Epoch: 24/50: 100%|#| 468/468 [00:43<00:00, 10.79it/s, Loss 0.2009 | accuracy_logits 0.933]\n",
      "100%|####| 156/156 [00:04<00:00, 35.82it/s, Loss 0.3371 | accuracy_logits 0.853]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 4.785986584612353e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "- Param group: \n",
      "\tinitial_lr: 8e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 6.381315446149805e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "\n",
      "Epoch: 25/50: 100%|#| 468/468 [00:43<00:00, 10.78it/s, Loss 0.1965 | accuracy_logits 0.932]\n",
      "100%|####| 156/156 [00:04<00:00, 35.34it/s, Loss 0.3388 | accuracy_logits 0.852]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 4.307387926151118e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "- Param group: \n",
      "\tinitial_lr: 8e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 5.7431839015348245e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "\n",
      "Epoch: 26/50: 100%|#| 468/468 [00:43<00:00, 10.74it/s, Loss 0.1944 | accuracy_logits 0.934]\n",
      "100%|####| 156/156 [00:04<00:00, 35.50it/s, Loss 0.3458 | accuracy_logits 0.851]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 3.876649133536006e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "- Param group: \n",
      "\tinitial_lr: 8e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 5.168865511381342e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "\n",
      "Epoch: 27/50: 100%|#| 468/468 [00:43<00:00, 10.73it/s, Loss 0.1922 | accuracy_logits 0.935]\n",
      "100%|####| 156/156 [00:04<00:00, 35.83it/s, Loss 0.3410 | accuracy_logits 0.853]\n",
      "Epoch    26: reducing learning rate of group 0 to 1.9383e-06.\n",
      "Epoch    26: reducing learning rate of group 1 to 2.5844e-06.\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 3.488984220182406e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "- Param group: \n",
      "\tinitial_lr: 8e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 4.651978960243208e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "\n",
      "Epoch: 28/50: 100%|#| 468/468 [00:43<00:00, 10.71it/s, Loss 0.1927 | accuracy_logits 0.936]\n",
      "100%|####| 156/156 [00:04<00:00, 35.54it/s, Loss 0.3347 | accuracy_logits 0.856]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 3.1400857981641657e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "- Param group: \n",
      "\tinitial_lr: 8e-05\n",
      "\teps: 1e-08\n",
      "\tlr: 4.186781064218888e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tweight_decay: 0.011\n",
      "\n",
      "Epoch: 29/50:   7%| | 32/468 [00:03<00:40, 10.73it/s, Loss 0.1864 | accuracy_logits 0.940]^C\n",
      "Process Process-562:\n",
      "Process Process-563:\n",
      "Process Process-561:\n",
      "Process Process-564:\n",
      "Process Process-565:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 40, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 40, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/working_directory/ml/pytorch-my_examples/SiameseNetworks/dataflow.py\", line 192, in __getitem__\n",
      "    (x1, x2), y = self.ds[index]\n",
      "  File \"/home/working_directory/ml/pytorch-my_examples/SiameseNetworks/dataflow.py\", line 185, in __getitem__\n",
      "    x2, y2 = self.ds[i2]\n",
      "  File \"/home/working_directory/ml/pytorch-my_examples/SiameseNetworks/dataflow.py\", line 63, in __getitem__\n",
      "    return self._get_image(self.data_ids[index]), self._get_label(self.data_ids[index])\n",
      "  File \"/home/working_directory/ml/pytorch-my_examples/SiameseNetworks/dataflow.py\", line 52, in _get_image\n",
      "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 train_model_with_oneshot_eval.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
