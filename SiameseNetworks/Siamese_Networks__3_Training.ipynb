{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verification task or Siamese neural networks training\n",
    "\n",
    "This notebook presents the paper [\"Siamese Neural Networks for One-shot Image Recognition\"](https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf) coded with PyTorch framework. \n",
    "\n",
    "In this part we train Siamese network on the Omniglot dataset to perform the classification task to distinguish two images of the same class or different classes.\n",
    "\n",
    "\n",
    "References:\n",
    "- [paper](https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf)\n",
    "- [omniglot](https://github.com/brendenlake/omniglot)\n",
    "- [keras-oneshot](https://github.com/sorenbouma/keras-oneshot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAS_GPU = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup dataflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataflow import OmniglotDataset, SameOrDifferentPairsDataset, PairTransformedDataset\n",
    "from common_utils.imgaug import RandomAffine, RandomApply\n",
    "from common_utils.dataflow import TransformedDataset, OnGPUDataLoader, ResizedDataset\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from torch.utils.data import DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "\n",
    "OMNIGLOT_REPO_PATH='omniglot'\n",
    "\n",
    "TRAIN_DATA_PATH = os.path.join(OMNIGLOT_REPO_PATH, 'python', 'images_background')\n",
    "train_alphabets = !ls {TRAIN_DATA_PATH}\n",
    "train_alphabets = list(train_alphabets)\n",
    "\n",
    "TEST_DATA_PATH = os.path.join(OMNIGLOT_REPO_PATH, 'python', 'images_evaluation')\n",
    "test_alphabets = !ls {TEST_DATA_PATH}\n",
    "test_alphabets = list(test_alphabets)\n",
    "\n",
    "assert len(train_alphabets) > 1 and len(test_alphabets) > 1, \"%s \\n %s\" % (train_alphabets[0], test_alphabets[0])\n",
    "\n",
    "train_alphabet_char_id_drawer_ids = {}\n",
    "for a in train_alphabets:\n",
    "    res = !ls \"{os.path.join(TRAIN_DATA_PATH, a)}\"\n",
    "    char_ids = list(res)\n",
    "    train_alphabet_char_id_drawer_ids[a] = {}\n",
    "    for char_id in char_ids:\n",
    "        res = !ls \"{os.path.join(TRAIN_DATA_PATH, a, char_id)}\"\n",
    "        train_alphabet_char_id_drawer_ids[a][char_id] = [_id[:-4] for _id in list(res)]\n",
    "        \n",
    "        \n",
    "test_alphabet_char_id_drawer_ids = {}\n",
    "for a in test_alphabets:\n",
    "    res = !ls \"{os.path.join(TEST_DATA_PATH, a)}\"\n",
    "    char_ids = list(res)\n",
    "    test_alphabet_char_id_drawer_ids[a] = {}\n",
    "    for char_id in char_ids:\n",
    "        res = !ls \"{os.path.join(TEST_DATA_PATH, a, char_id)}\"\n",
    "        test_alphabet_char_id_drawer_ids[a][char_id] = [_id[:-4] for _id in list(res)]\n",
    "\n",
    "\n",
    "# Sample 12 drawers out of 20\n",
    "all_drawers_ids = np.arange(20) \n",
    "train_drawers_ids = np.random.choice(all_drawers_ids, size=12, replace=False)\n",
    "# Sample 4 drawers out of remaining 8\n",
    "val_drawers_ids = np.random.choice(list(set(all_drawers_ids) - set(train_drawers_ids)), size=4, replace=False)\n",
    "test_drawers_ids = np.array(list(set(all_drawers_ids) - set(val_drawers_ids) - set(train_drawers_ids)))\n",
    "\n",
    "def create_str_drawers_ids(drawers_ids):\n",
    "    return [\"_{0:0>2}\".format(_id) for _id in drawers_ids]\n",
    "\n",
    "train_drawers_ids = create_str_drawers_ids(train_drawers_ids)\n",
    "val_drawers_ids = create_str_drawers_ids(val_drawers_ids)\n",
    "test_drawers_ids = create_str_drawers_ids(test_drawers_ids)\n",
    "\n",
    "train_ds = OmniglotDataset(\"Train\", data_path=TRAIN_DATA_PATH, \n",
    "                           alphabet_char_id_drawers_ids=train_alphabet_char_id_drawer_ids, \n",
    "                           drawers_ids=train_drawers_ids)\n",
    "\n",
    "val_ds = OmniglotDataset(\"Test\", data_path=TEST_DATA_PATH, \n",
    "                         alphabet_char_id_drawers_ids=test_alphabet_char_id_drawer_ids, \n",
    "                         drawers_ids=val_drawers_ids)\n",
    "\n",
    "test_ds = OmniglotDataset(\"Test\", data_path=TEST_DATA_PATH, \n",
    "                          alphabet_char_id_drawers_ids=test_alphabet_char_id_drawer_ids, \n",
    "                          drawers_ids=test_drawers_ids)\n",
    "\n",
    "#train_ds = ResizedDataset(train_ds, output_size=(80, 80))\n",
    "#val_ds = ResizedDataset(val_ds, output_size=(80, 80))\n",
    "#test_ds = ResizedDataset(test_ds, output_size=(80, 80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 10000, 10000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pairs = SameOrDifferentPairsDataset(train_ds, nb_pairs=int(30e3))\n",
    "val_pairs = SameOrDifferentPairsDataset(val_ds, nb_pairs=int(10e3))\n",
    "test_pairs = SameOrDifferentPairsDataset(test_ds, nb_pairs=int(10e3))\n",
    "\n",
    "len(train_pairs), len(val_pairs), len(test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_aug = Compose([\n",
    "    RandomApply(\n",
    "        RandomAffine(rotation=(-10, 10), scale=(0.8, 1.2), translate=(-0.05, 0.05)),\n",
    "        proba=0.5\n",
    "    ),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "test_data_aug = Compose([\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "y_transform = lambda y: torch.FloatTensor([y])\n",
    "\n",
    "train_aug_pairs = PairTransformedDataset(train_pairs, x_transforms=train_data_aug, y_transforms=y_transform)\n",
    "val_aug_pairs = PairTransformedDataset(val_pairs, x_transforms=test_data_aug, y_transforms=y_transform)\n",
    "test_aug_pairs = PairTransformedDataset(test_pairs, x_transforms=test_data_aug, y_transforms=y_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(468, 156, 157)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "_DataLoader = OnGPUDataLoader if HAS_GPU and torch.cuda.is_available() else DataLoader\n",
    "\n",
    "train_batches = _DataLoader(train_aug_pairs, batch_size=batch_size, \n",
    "                            shuffle=True, num_workers=12, \n",
    "                            drop_last=True)\n",
    "\n",
    "val_batches = _DataLoader(val_aug_pairs, batch_size=batch_size, \n",
    "                          shuffle=True, num_workers=12,\n",
    "                          pin_memory=True, drop_last=True)\n",
    "\n",
    "test_batches = _DataLoader(test_aug_pairs, batch_size=batch_size, \n",
    "                           shuffle=False, num_workers=12,                   \n",
    "                           pin_memory=True, drop_last=False)\n",
    "\n",
    "\n",
    "len(train_batches), len(val_batches), len(test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 105, 105]) torch.Size([64, 1, 105, 105]) torch.Size([64, 1])\n",
      "<class 'torch.cuda.FloatTensor'> <class 'torch.cuda.FloatTensor'> <class 'torch.cuda.FloatTensor'>\n"
     ]
    }
   ],
   "source": [
    "for (x1, x2), y in train_batches:\n",
    "    print(x1.size(), x2.size(), y.size())\n",
    "    print(type(x1), type(x1), type(y))    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup model, loss function and optimisation algorithm\n",
    "\n",
    "#### Weight regularization\n",
    "\n",
    "L2 weights regularization: \n",
    "\n",
    "#### Loss function\n",
    "\n",
    "Binary cross-entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.nn.functional import sigmoid\n",
    "from torch.optim import Adam, RMSprop, SGD\n",
    "from torch.optim.lr_scheduler import ExponentialLR, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from common_utils.training_utils import train_one_epoch, validate, write_csv_log, write_conf_log, verbose_optimizer, save_checkpoint\n",
    "from common_utils.training_utils import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import SiameseNetworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_net = SiameseNetworks(input_shape=(105, 105, 1))\n",
    "if HAS_GPU and torch.cuda.is_available():\n",
    "    siamese_net = siamese_net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {\n",
    "    'weight_decay': 0.01,\n",
    "    \n",
    "    'lr_features': 0.00006,\n",
    "    'lr_classifier': 0.00008,\n",
    "    \n",
    "    'n_epochs': 50,    \n",
    "    'gamma': 0.77\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_logits(y_logits, y_true):\n",
    "    y_pred = sigmoid(y_logits).data\n",
    "    return accuracy(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = BCEWithLogitsLoss()\n",
    "if HAS_GPU and torch.cuda.is_available():\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.cuda.FloatTensor'> <class 'torch.cuda.FloatTensor'> torch.Size([64, 1]) torch.Size([64, 1])\n",
      "Loss :  \n",
      " 0.6933\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Accuracy :  0.53125\n"
     ]
    }
   ],
   "source": [
    "# Test single forward pass and loss function computation\n",
    "siamese_net.eval()\n",
    "for i, ((batch_x1, batch_x2), batch_y) in enumerate(train_batches):\n",
    "    \n",
    "    batch_x1 = Variable(batch_x1, requires_grad=True)\n",
    "    batch_x2 = Variable(batch_x2, requires_grad=True)    \n",
    "    batch_y = Variable(batch_y)\n",
    "    batch_y_logits = siamese_net(batch_x1, batch_x2)\n",
    "    print(type(batch_y.data), type(batch_y_logits.data), batch_y.size(), batch_y_logits.size())    \n",
    "    loss = criterion(batch_y_logits, batch_y)\n",
    "    print(\"Loss : \", loss.data)\n",
    "    \n",
    "    print(\"Accuracy : \", accuracy_logits(batch_y_logits.data, batch_y.data))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam([{\n",
    "    'params': siamese_net.net.features.parameters(),\n",
    "    'lr': conf['lr_features'],    \n",
    "}, {\n",
    "    'params': siamese_net.classifier.parameters(),\n",
    "    'lr': conf['lr_classifier']\n",
    "}],\n",
    "    weight_decay=conf['weight_decay']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we define L2 regularization weights through optimizer API as `weight_decay` parameter, [ref](http://pytorch.org/docs/master/optim.html?highlight=adam#torch.optim.Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr <- lr_init * gamma ** epoch\n",
    "scheduler = ExponentialLR(optimizer, gamma=conf['gamma'])\n",
    "onplateau_scheduler = ReduceLROnPlateau(optimizer, factor=0.5, patience=2, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "logs_path = os.path.join('logs', 'seamese_networks_verification_task_%s' % (now.strftime(\"%Y%m%d_%H%M\")))\n",
    "if not os.path.exists(logs_path):\n",
    "    os.makedirs(logs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tlr: 6e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "- Param group: \n",
      "\tlr: 8e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 8e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|##########| 468/468 [00:42<00:00, 11.02it/s, Loss 0.6317 | accuracy_logits 0.567]\n",
      "100%|##########| 156/156 [00:04<00:00, 34.97it/s, Loss 0.6219 | accuracy_logits 0.611]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tlr: 4.6200000000000005e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "- Param group: \n",
      "\tlr: 6.16e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 8e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2/50: 100%|##########| 468/468 [00:43<00:00, 10.88it/s, Loss 0.5921 | accuracy_logits 0.654]\n",
      "100%|##########| 156/156 [00:04<00:00, 34.55it/s, Loss 0.5797 | accuracy_logits 0.694]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tlr: 3.5574e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "- Param group: \n",
      "\tlr: 4.7432e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 8e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3/50: 100%|##########| 468/468 [00:43<00:00, 10.78it/s, Loss 0.5429 | accuracy_logits 0.721]\n",
      "100%|##########| 156/156 [00:04<00:00, 34.51it/s, Loss 0.5546 | accuracy_logits 0.705]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tlr: 2.7391980000000003e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "- Param group: \n",
      "\tlr: 3.6522640000000004e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 8e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4/50: 100%|##########| 468/468 [00:43<00:00, 10.87it/s, Loss 0.4975 | accuracy_logits 0.762]\n",
      "100%|##########| 156/156 [00:04<00:00, 34.46it/s, Loss 0.5334 | accuracy_logits 0.725]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tlr: 2.1091824600000002e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "- Param group: \n",
      "\tlr: 2.8122432800000004e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 8e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5/50: 100%|##########| 468/468 [00:43<00:00, 10.86it/s, Loss 0.4611 | accuracy_logits 0.791]\n",
      "100%|##########| 156/156 [00:04<00:00, 34.32it/s, Loss 0.5067 | accuracy_logits 0.756]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tlr: 1.6240704942e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "- Param group: \n",
      "\tlr: 2.1654273256e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 8e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6/50: 100%|##########| 468/468 [00:43<00:00, 10.86it/s, Loss 0.4326 | accuracy_logits 0.808]\n",
      "100%|##########| 156/156 [00:04<00:00, 34.82it/s, Loss 0.4967 | accuracy_logits 0.771]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tlr: 1.2505342805340002e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "- Param group: \n",
      "\tlr: 1.667379040712e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 8e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 7/50: 100%|##########| 468/468 [00:43<00:00, 10.85it/s, Loss 0.4099 | accuracy_logits 0.826]\n",
      "100%|##########| 156/156 [00:04<00:00, 34.85it/s, Loss 0.4960 | accuracy_logits 0.765]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tlr: 9.629113960111801e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "- Param group: \n",
      "\tlr: 1.2838818613482402e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 8e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 8/50: 100%|##########| 468/468 [00:43<00:00, 10.79it/s, Loss 0.3901 | accuracy_logits 0.838]\n",
      "100%|##########| 156/156 [00:04<00:00, 35.14it/s, Loss 0.4937 | accuracy_logits 0.773]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tlr: 7.4144177492860875e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "- Param group: \n",
      "\tlr: 9.88589033238145e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 8e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9/50: 100%|##########| 468/468 [00:43<00:00, 10.79it/s, Loss 0.3804 | accuracy_logits 0.844]\n",
      "100%|##########| 156/156 [00:04<00:00, 34.35it/s, Loss 0.4850 | accuracy_logits 0.780]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tlr: 5.709101666950288e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "- Param group: \n",
      "\tlr: 7.612135555933717e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 8e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 10/50: 100%|##########| 468/468 [00:43<00:00, 10.75it/s, Loss 0.3695 | accuracy_logits 0.850]\n",
      "100%|##########| 156/156 [00:04<00:00, 35.15it/s, Loss 0.4825 | accuracy_logits 0.777]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tlr: 4.396008283551722e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "- Param group: \n",
      "\tlr: 5.861344378068963e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 8e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 11/50: 100%|##########| 468/468 [00:43<00:00, 10.75it/s, Loss 0.3641 | accuracy_logits 0.852]\n",
      "100%|##########| 156/156 [00:04<00:00, 34.63it/s, Loss 0.4753 | accuracy_logits 0.778]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tlr: 3.3849263783348255e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "- Param group: \n",
      "\tlr: 4.513235171113101e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 8e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 12/50: 100%|##########| 468/468 [00:43<00:00, 10.66it/s, Loss 0.3542 | accuracy_logits 0.858]\n",
      "100%|##########| 156/156 [00:04<00:00, 34.72it/s, Loss 0.4724 | accuracy_logits 0.782]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tlr: 2.606393311317816e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "- Param group: \n",
      "\tlr: 3.4751910817570877e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 8e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 13/50: 100%|##########| 468/468 [00:43<00:00, 10.66it/s, Loss 0.3524 | accuracy_logits 0.860]\n",
      "100%|##########| 156/156 [00:04<00:00, 34.67it/s, Loss 0.4805 | accuracy_logits 0.779]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tlr: 2.006922849714718e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "- Param group: \n",
      "\tlr: 2.6758971329529576e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 8e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 14/50: 100%|##########| 468/468 [00:44<00:00, 10.61it/s, Loss 0.3499 | accuracy_logits 0.860]\n",
      "100%|##########| 156/156 [00:04<00:00, 35.05it/s, Loss 0.4833 | accuracy_logits 0.783]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tlr: 1.5453305942803332e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "- Param group: \n",
      "\tlr: 2.060440792373778e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 8e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15/50: 100%|##########| 468/468 [00:44<00:00, 10.63it/s, Loss 0.3473 | accuracy_logits 0.862]\n",
      "100%|##########| 156/156 [00:04<00:00, 35.21it/s, Loss 0.4755 | accuracy_logits 0.784]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    14: reducing learning rate of group 0 to 7.7267e-07.\n",
      "Epoch    14: reducing learning rate of group 1 to 1.0302e-06.\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tlr: 1.1899045575958565e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "- Param group: \n",
      "\tlr: 1.5865394101278086e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 8e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 16/50: 100%|##########| 468/468 [00:44<00:00, 10.60it/s, Loss 0.3429 | accuracy_logits 0.864]\n",
      "100%|##########| 156/156 [00:04<00:00, 34.81it/s, Loss 0.4745 | accuracy_logits 0.785]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tlr: 9.162265093488095e-07\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "- Param group: \n",
      "\tlr: 1.2216353457984127e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 8e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 17/50: 100%|##########| 468/468 [00:44<00:00, 10.59it/s, Loss 0.3447 | accuracy_logits 0.864]\n",
      "100%|##########| 156/156 [00:04<00:00, 35.47it/s, Loss 0.4742 | accuracy_logits 0.784]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tlr: 7.054944121985834e-07\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "- Param group: \n",
      "\tlr: 9.406592162647779e-07\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 8e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 18/50: 100%|##########| 468/468 [00:44<00:00, 10.59it/s, Loss 0.3428 | accuracy_logits 0.865]\n",
      "100%|##########| 156/156 [00:04<00:00, 34.88it/s, Loss 0.4719 | accuracy_logits 0.785]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tlr: 5.432306973929092e-07\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "- Param group: \n",
      "\tlr: 7.24307596523879e-07\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 8e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 19/50: 100%|##########| 468/468 [00:44<00:00, 10.62it/s, Loss 0.3424 | accuracy_logits 0.866]\n",
      "100%|##########| 156/156 [00:04<00:00, 34.90it/s, Loss 0.4733 | accuracy_logits 0.786]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tlr: 4.1828763699254005e-07\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "- Param group: \n",
      "\tlr: 5.577168493233868e-07\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 8e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 20/50: 100%|##########| 468/468 [00:44<00:00, 10.59it/s, Loss 0.3410 | accuracy_logits 0.866]\n",
      "100%|##########| 156/156 [00:04<00:00, 34.37it/s, Loss 0.4732 | accuracy_logits 0.786]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tlr: 3.220814804842559e-07\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "- Param group: \n",
      "\tlr: 4.294419739790079e-07\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 8e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 21/50: 100%|##########| 468/468 [00:44<00:00, 10.58it/s, Loss 0.3380 | accuracy_logits 0.868]\n",
      "100%|##########| 156/156 [00:04<00:00, 35.26it/s, Loss 0.4708 | accuracy_logits 0.788]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tlr: 2.4800273997287704e-07\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "- Param group: \n",
      "\tlr: 3.3067031996383607e-07\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 8e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 22/50: 100%|##########| 468/468 [00:44<00:00, 10.60it/s, Loss 0.3414 | accuracy_logits 0.864]\n",
      "100%|##########| 156/156 [00:04<00:00, 34.72it/s, Loss 0.4718 | accuracy_logits 0.787]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tlr: 1.9096210977911532e-07\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "- Param group: \n",
      "\tlr: 2.5461614637215375e-07\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 8e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 23/50: 100%|##########| 468/468 [00:44<00:00, 10.57it/s, Loss 0.3377 | accuracy_logits 0.868]\n",
      "100%|##########| 156/156 [00:04<00:00, 34.74it/s, Loss 0.4735 | accuracy_logits 0.786]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tlr: 1.470408245299188e-07\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "- Param group: \n",
      "\tlr: 1.960544327065584e-07\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 8e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 24/50: 100%|##########| 468/468 [00:44<00:00, 10.58it/s, Loss 0.3383 | accuracy_logits 0.868]\n",
      "100%|##########| 156/156 [00:04<00:00, 34.84it/s, Loss 0.4723 | accuracy_logits 0.787]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    23: reducing learning rate of group 0 to 7.3520e-08.\n",
      "Epoch    23: reducing learning rate of group 1 to 9.8027e-08.\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tlr: 1.1322143488803749e-07\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "- Param group: \n",
      "\tlr: 1.5096191318405e-07\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 8e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 25/50: 100%|##########| 468/468 [00:44<00:00, 10.58it/s, Loss 0.3389 | accuracy_logits 0.866]\n",
      "100%|##########| 156/156 [00:04<00:00, 34.81it/s, Loss 0.4732 | accuracy_logits 0.787]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tlr: 8.718050486378885e-08\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "- Param group: \n",
      "\tlr: 1.1624067315171848e-07\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 8e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 26/50: 100%|##########| 468/468 [00:44<00:00, 10.56it/s, Loss 0.3371 | accuracy_logits 0.869]\n",
      "100%|##########| 156/156 [00:04<00:00, 34.81it/s, Loss 0.4727 | accuracy_logits 0.788]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tlr: 6.712898874511743e-08\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "- Param group: \n",
      "\tlr: 8.950531832682324e-08\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 8e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 27/50: 100%|##########| 468/468 [00:44<00:00, 10.55it/s, Loss 0.3358 | accuracy_logits 0.870]\n",
      "100%|##########| 156/156 [00:04<00:00, 34.83it/s, Loss 0.4729 | accuracy_logits 0.787]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    26: reducing learning rate of group 0 to 3.3564e-08.\n",
      "Epoch    26: reducing learning rate of group 1 to 4.4753e-08.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tlr: 5.168932133374042e-08\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "- Param group: \n",
      "\tlr: 6.89190951116539e-08\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 8e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 28/50: 100%|##########| 468/468 [00:44<00:00, 10.59it/s, Loss 0.3351 | accuracy_logits 0.870]\n",
      "100%|##########| 156/156 [00:04<00:00, 34.53it/s, Loss 0.4727 | accuracy_logits 0.787]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tlr: 3.980077742698012e-08\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "- Param group: \n",
      "\tlr: 5.3067703235973496e-08\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 8e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 29/50: 100%|##########| 468/468 [00:44<00:00, 10.62it/s, Loss 0.3391 | accuracy_logits 0.866]\n",
      "100%|##########| 156/156 [00:04<00:00, 35.23it/s, Loss 0.4731 | accuracy_logits 0.787]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tlr: 3.0646598618774695e-08\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "- Param group: \n",
      "\tlr: 4.08621314916996e-08\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 8e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 30/50: 100%|##########| 468/468 [00:44<00:00, 10.59it/s, Loss 0.3370 | accuracy_logits 0.868]\n",
      "100%|##########| 156/156 [00:04<00:00, 34.91it/s, Loss 0.4734 | accuracy_logits 0.787]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    29: reducing learning rate of group 0 to 1.5323e-08.\n",
      "Epoch    29: reducing learning rate of group 1 to 2.0431e-08.\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tlr: 2.3597880936456514e-08\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "- Param group: \n",
      "\tlr: 3.1463841248608685e-08\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 8e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 31/50: 100%|##########| 468/468 [00:44<00:00, 10.60it/s, Loss 0.3361 | accuracy_logits 0.871]\n",
      "100%|##########| 156/156 [00:04<00:00, 35.22it/s, Loss 0.4733 | accuracy_logits 0.787]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tlr: 1.8170368321071516e-08\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "- Param group: \n",
      "\tlr: 2.422715776142869e-08\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 8e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 32/50: 100%|##########| 468/468 [00:44<00:00, 10.60it/s, Loss 0.3391 | accuracy_logits 0.867]\n",
      "100%|##########| 156/156 [00:04<00:00, 34.64it/s, Loss 0.4731 | accuracy_logits 0.787]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tlr: 1.3991183607225069e-08\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "- Param group: \n",
      "\tlr: 1.865491147630009e-08\n",
      "\tbetas: (0.9, 0.999)\n",
      "\tinitial_lr: 8e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 33/50:  73%|#######2  | 340/468 [00:32<00:12, 10.66it/s, Loss 0.3374 | accuracy_logits 0.868]Process Process-3272:\n",
      "Process Process-3281:\n",
      "Process Process-3283:\n",
      "Process Process-3276:\n",
      "Process Process-3275:\n",
      "Process Process-3277:\n",
      "Process Process-3273:\n",
      "Process Process-3278:\n",
      "Process Process-3279:\n",
      "Process Process-3274:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-3280:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-3282:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 40, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 40, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/working_directory/ml/pytorch-my_examples/SiameseNetworks/dataflow.py\", line 132, in __getitem__\n",
      "    x1 = self.x_transforms(x1)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torchvision/transforms.py\", line 34, in __call__\n",
      "    img = t(img)\n",
      "KeyboardInterrupt\n",
      "  File \"../common_utils/imgaug.py\", line 44, in __call__\n",
      "    return self.transform(img)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"../common_utils/imgaug.py\", line 111, in __call__\n",
      "    borderMode=cv2.BORDER_REPLICATE)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Epoch: 33/50:  73%|#######2  | 341/468 [00:32<00:12, 10.53it/s, Loss 0.3373 | accuracy_logits 0.868]\n"
     ]
    }
   ],
   "source": [
    "write_conf_log(logs_path, \"{}\".format(conf))\n",
    "write_conf_log(logs_path, verbose_optimizer(optimizer))\n",
    "\n",
    "write_csv_log(logs_path, \"epoch,train_loss,train_acc,val_loss,val_acc\")\n",
    "\n",
    "best_acc = 0.0\n",
    "for epoch in range(conf['n_epochs']):\n",
    "    scheduler.step()\n",
    "    # Verbose learning rates:\n",
    "    print(verbose_optimizer(optimizer))\n",
    "\n",
    "    # train for one epoch\n",
    "    ret = train_one_epoch(siamese_net, train_batches, \n",
    "                          criterion, optimizer,                                               \n",
    "                          epoch, conf['n_epochs'], avg_metrics=[accuracy_logits,])\n",
    "    if ret is None:\n",
    "        break\n",
    "    train_loss, train_acc = ret\n",
    "\n",
    "    # evaluate on validation set\n",
    "    ret = validate(siamese_net, val_batches, criterion, avg_metrics=[accuracy_logits, ])\n",
    "    if ret is None:\n",
    "        break\n",
    "    val_loss, val_acc = ret\n",
    "    \n",
    "    onplateau_scheduler.step(val_loss)\n",
    "\n",
    "    # Write a csv log file\n",
    "    write_csv_log(logs_path, \"%i,%f,%f,%f,%f\" % (epoch, train_loss, train_acc, val_loss, val_acc))\n",
    "\n",
    "    # remember best accuracy and save checkpoint\n",
    "    if val_acc > best_acc:\n",
    "        best_prec1 = max(val_acc, best_acc)\n",
    "        save_checkpoint(logs_path, 'val_acc', \n",
    "                        {'epoch': epoch + 1,\n",
    "                         'state_dict': siamese_net.state_dict(),\n",
    "                         'val_acc': val_acc,           \n",
    "                         'optimizer': optimizer.state_dict()})        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference on testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common_utils.training_utils import load_checkpoint\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load checkpoint: logs/seamese_networks_verification_task_20171123_2101/model_val_acc=0.7871.pth.tar\n"
     ]
    }
   ],
   "source": [
    "best_model_filenames = glob(os.path.join(logs_path, \"model_val_acc=*\"))\n",
    "assert len(best_model_filenames) == 1\n",
    "load_checkpoint(best_model_filenames[0], siamese_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 157/157 [00:04<00:00, 34.73it/s, Loss 0.4653 | accuracy_logits 0.784]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.46532357335090635, 0.7845)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate on validation set\n",
    "test_loss, test_acc = validate(siamese_net, test_batches, criterion, avg_metrics=[accuracy_logits, ])\n",
    "test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 6e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "- Param group: \n",
      "\tinitial_lr: 7e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 7e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\n",
      "Epoch: 1/50: 100%|#| 468/468 [00:43<00:00, 10.80it/s, Loss 0.6218 | accuracy_logits 0.588]\n",
      "100%|####| 156/156 [00:04<00:00, 34.25it/s, Loss 0.6078 | accuracy_logits 0.630]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 4.7340000000000004e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "- Param group: \n",
      "\tinitial_lr: 7e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 5.523e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\n",
      "Epoch: 2/50: 100%|#| 468/468 [00:43<00:00, 10.80it/s, Loss 0.5789 | accuracy_logits 0.680]\n",
      "100%|####| 156/156 [00:04<00:00, 34.74it/s, Loss 0.5836 | accuracy_logits 0.677]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 3.735126000000001e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "- Param group: \n",
      "\tinitial_lr: 7e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 4.357647e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\n",
      "Epoch: 3/50: 100%|#| 468/468 [00:43<00:00, 10.84it/s, Loss 0.5233 | accuracy_logits 0.737]\n",
      "100%|####| 156/156 [00:04<00:00, 34.42it/s, Loss 0.5320 | accuracy_logits 0.734]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 2.9470144140000006e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "- Param group: \n",
      "\tinitial_lr: 7e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 3.438183483e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\n",
      "Epoch: 4/50: 100%|#| 468/468 [00:42<00:00, 10.91it/s, Loss 0.4764 | accuracy_logits 0.778]\n",
      "100%|####| 156/156 [00:04<00:00, 34.26it/s, Loss 0.5283 | accuracy_logits 0.749]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 2.3251943726460004e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "- Param group: \n",
      "\tinitial_lr: 7e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 2.712726768087e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\n",
      "Epoch: 5/50: 100%|#| 468/468 [00:42<00:00, 10.91it/s, Loss 0.4312 | accuracy_logits 0.812]\n",
      "100%|####| 156/156 [00:04<00:00, 34.71it/s, Loss 0.4950 | accuracy_logits 0.769]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 1.8345783600176945e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "- Param group: \n",
      "\tinitial_lr: 7e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 2.1403414200206433e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\n",
      "Epoch: 6/50: 100%|#| 468/468 [00:43<00:00, 10.85it/s, Loss 0.4026 | accuracy_logits 0.828]\n",
      "100%|####| 156/156 [00:04<00:00, 34.93it/s, Loss 0.4978 | accuracy_logits 0.765]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 1.447482326053961e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "- Param group: \n",
      "\tinitial_lr: 7e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 1.6887293803962875e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\n",
      "Epoch: 7/50: 100%|#| 468/468 [00:43<00:00, 10.86it/s, Loss 0.3757 | accuracy_logits 0.846]\n",
      "100%|####| 156/156 [00:04<00:00, 35.05it/s, Loss 0.4800 | accuracy_logits 0.774]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 1.1420635552565753e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "- Param group: \n",
      "\tinitial_lr: 7e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 1.332407481132671e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\n",
      "Epoch: 8/50: 100%|#| 468/468 [00:43<00:00, 10.85it/s, Loss 0.3571 | accuracy_logits 0.856]\n",
      "100%|####| 156/156 [00:04<00:00, 34.53it/s, Loss 0.4730 | accuracy_logits 0.782]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 9.01088145097438e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "- Param group: \n",
      "\tinitial_lr: 7e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 1.0512695026136775e-05\n",
      "\tbetas: (0.9, 0.999)\n",
      "\n",
      "Epoch: 9/50: 100%|#| 468/468 [00:43<00:00, 10.81it/s, Loss 0.3430 | accuracy_logits 0.865]\n",
      "100%|####| 156/156 [00:04<00:00, 34.74it/s, Loss 0.4624 | accuracy_logits 0.790]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 7.1095854648187855e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "- Param group: \n",
      "\tinitial_lr: 7e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 8.294516375621916e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\n",
      "Epoch: 10/50: 100%|#| 468/468 [00:43<00:00, 10.79it/s, Loss 0.3324 | accuracy_logits 0.871]\n",
      "100%|####| 156/156 [00:04<00:00, 35.07it/s, Loss 0.4593 | accuracy_logits 0.790]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 5.609462931742022e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "- Param group: \n",
      "\tinitial_lr: 7e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 6.544373420365691e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\n",
      "Epoch: 11/50: 100%|#| 468/468 [00:43<00:00, 10.76it/s, Loss 0.3230 | accuracy_logits 0.877]\n",
      "100%|####| 156/156 [00:04<00:00, 35.06it/s, Loss 0.4609 | accuracy_logits 0.790]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 4.425866253144456e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "- Param group: \n",
      "\tinitial_lr: 7e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 5.1635106286685316e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\n",
      "Epoch: 12/50: 100%|#| 468/468 [00:43<00:00, 10.75it/s, Loss 0.3195 | accuracy_logits 0.879]\n",
      "100%|####| 156/156 [00:04<00:00, 34.68it/s, Loss 0.4539 | accuracy_logits 0.793]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 3.4920084737309754e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "- Param group: \n",
      "\tinitial_lr: 7e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 4.074009886019471e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\n",
      "Epoch: 13/50: 100%|#| 468/468 [00:43<00:00, 10.71it/s, Loss 0.3107 | accuracy_logits 0.880]\n",
      "100%|####| 156/156 [00:04<00:00, 34.97it/s, Loss 0.4560 | accuracy_logits 0.789]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 2.75519468577374e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "- Param group: \n",
      "\tinitial_lr: 7e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 3.2143938000693627e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\n",
      "Epoch: 14/50: 100%|#| 468/468 [00:43<00:00, 10.68it/s, Loss 0.3052 | accuracy_logits 0.884]\n",
      "100%|####| 156/156 [00:04<00:00, 34.89it/s, Loss 0.4499 | accuracy_logits 0.791]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 2.173848607075481e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "- Param group: \n",
      "\tinitial_lr: 7e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 2.5361567082547274e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\n",
      "Epoch: 15/50: 100%|#| 468/468 [00:43<00:00, 10.65it/s, Loss 0.3052 | accuracy_logits 0.885]\n",
      "100%|####| 156/156 [00:04<00:00, 35.10it/s, Loss 0.4496 | accuracy_logits 0.792]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 1.7151665509825543e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "- Param group: \n",
      "\tinitial_lr: 7e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 2.0010276428129798e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\n",
      "Epoch: 16/50: 100%|#| 468/468 [00:44<00:00, 10.62it/s, Loss 0.3028 | accuracy_logits 0.885]\n",
      "100%|####| 156/156 [00:04<00:00, 34.58it/s, Loss 0.4483 | accuracy_logits 0.792]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 1.3532664087252355e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "- Param group: \n",
      "\tinitial_lr: 7e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 1.5788108101794412e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\n",
      "Epoch: 17/50: 100%|#| 468/468 [00:44<00:00, 10.63it/s, Loss 0.3002 | accuracy_logits 0.887]\n",
      "100%|####| 156/156 [00:04<00:00, 34.95it/s, Loss 0.4450 | accuracy_logits 0.795]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 1.0677271964842108e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "- Param group: \n",
      "\tinitial_lr: 7e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 1.2456817292315791e-06\n",
      "\tbetas: (0.9, 0.999)\n",
      "\n",
      "Epoch: 18/50: 100%|#| 468/468 [00:43<00:00, 10.68it/s, Loss 0.2970 | accuracy_logits 0.890]\n",
      "100%|####| 156/156 [00:04<00:00, 34.56it/s, Loss 0.4464 | accuracy_logits 0.794]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 8.424367580260424e-07\n",
      "\tbetas: (0.9, 0.999)\n",
      "- Param group: \n",
      "\tinitial_lr: 7e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 9.82842884363716e-07\n",
      "\tbetas: (0.9, 0.999)\n",
      "\n",
      "Epoch: 19/50: 100%|#| 468/468 [00:43<00:00, 10.64it/s, Loss 0.2960 | accuracy_logits 0.891]\n",
      "100%|####| 156/156 [00:04<00:00, 34.83it/s, Loss 0.4523 | accuracy_logits 0.793]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 6.646826020825476e-07\n",
      "\tbetas: (0.9, 0.999)\n",
      "- Param group: \n",
      "\tinitial_lr: 7e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 7.75463035762972e-07\n",
      "\tbetas: (0.9, 0.999)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/50: 100%|#| 468/468 [00:44<00:00, 10.61it/s, Loss 0.2982 | accuracy_logits 0.889]\n",
      "100%|####| 156/156 [00:04<00:00, 34.84it/s, Loss 0.4481 | accuracy_logits 0.795]\n",
      "Epoch    19: reducing learning rate of group 0 to 3.3234e-07.\n",
      "Epoch    19: reducing learning rate of group 1 to 3.8773e-07.\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 5.2443457304313e-07\n",
      "\tbetas: (0.9, 0.999)\n",
      "- Param group: \n",
      "\tinitial_lr: 7e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 6.11840335216985e-07\n",
      "\tbetas: (0.9, 0.999)\n",
      "\n",
      "Epoch: 21/50: 100%|#| 468/468 [00:44<00:00, 10.62it/s, Loss 0.2952 | accuracy_logits 0.890]\n",
      "100%|####| 156/156 [00:04<00:00, 35.06it/s, Loss 0.4475 | accuracy_logits 0.795]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 4.137788781310296e-07\n",
      "\tbetas: (0.9, 0.999)\n",
      "- Param group: \n",
      "\tinitial_lr: 7e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 4.827420244862011e-07\n",
      "\tbetas: (0.9, 0.999)\n",
      "\n",
      "Epoch: 22/50: 100%|#| 468/468 [00:44<00:00, 10.61it/s, Loss 0.2942 | accuracy_logits 0.892]\n",
      "100%|####| 156/156 [00:04<00:00, 34.94it/s, Loss 0.4462 | accuracy_logits 0.795]\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 3.264715348453824e-07\n",
      "\tbetas: (0.9, 0.999)\n",
      "- Param group: \n",
      "\tinitial_lr: 7e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 3.8088345731961274e-07\n",
      "\tbetas: (0.9, 0.999)\n",
      "\n",
      "Epoch: 23/50: 100%|#| 468/468 [00:44<00:00, 10.61it/s, Loss 0.2934 | accuracy_logits 0.892]\n",
      "100%|####| 156/156 [00:04<00:00, 34.90it/s, Loss 0.4468 | accuracy_logits 0.794]\n",
      "Epoch    22: reducing learning rate of group 0 to 1.6324e-07.\n",
      "Epoch    22: reducing learning rate of group 1 to 1.9044e-07.\n",
      "\n",
      "Optimizer: Adam\n",
      "- Param group: \n",
      "\tinitial_lr: 6e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 2.5758604099300674e-07\n",
      "\tbetas: (0.9, 0.999)\n",
      "- Param group: \n",
      "\tinitial_lr: 7e-05\n",
      "\tweight_decay: 0.01\n",
      "\teps: 1e-08\n",
      "\tlr: 3.0051704782517444e-07\n",
      "\tbetas: (0.9, 0.999)\n",
      "\n",
      "Epoch: 24/50:  41%|4| 194/468 [00:18<00:25, 10.58it/s, Loss 0.2898 | accuracy_logits 0.896]"
     ]
    }
   ],
   "source": [
    "!python3 train_verification_task.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
